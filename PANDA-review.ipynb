{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate cANcer graDe Assessment (PANDA) Challenge\n",
    "\n",
    "- Computer Vision / Image classification\n",
    "- main challenge of this task is dealing with images of extremely high resolution and large areas of empty space. So, effective locating the areas of concern and zooming them in would be the key to reach high LB score.\n",
    "- noisy data and train/test bias : solely relaying on CV was not really good strategy in this competition\n",
    "- metric : QWK \n",
    "\n",
    "- Datasets : Train set(10616), Test set(940?) -> Train set labeled by 2 different institution(Karolinska, Radboud)\n",
    "\n",
    "- Image size : not uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (N) Iafoss : PANDA concat tile pooling starter [0.79 LB]\n",
    "https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-0-79-lb <br>\n",
    "https://www.kaggle.com/iafoss/panda-16x128x128-tiles <br>\n",
    "https://www.kaggle.com/c/prostate-cancer-grade-assessment/discussion/169205 <br>\n",
    "https://github.com/iafoss/PANDA <br>\n",
    "\n",
    "### Data preprocessing\n",
    "- Tile extraction is based on my public pipeline with 128x128x128 tiles from intermediate resolution layer\n",
    "- Label noise removal(removal of the uncertain examples from training set based on the out of fold predictions. I excluded ~1400 Redbound and 300 Karalinska data, so my clean training set contains about 8700 items) gives ~0.005 public and 0.01+ private LB boost\n",
    "- tile cutout + tile selection augmentations\n",
    "- more advanced tile selection could give ~0.004 boost at private LB on average (and the maximum private LB score of 0.941)\n",
    "- LB was also not the best thing to trust because of severe noise, but some ppl tried to fit random seed as a hyperparameter. The right thing, in my opinion, in this competition was to find the balance between CV and LB, and trust to your intuition and the experience gained in the previous competitions.\n",
    "\n",
    "### Modeling\n",
    "- All my models are based on ResNeXt50, similar to my public kernel, with batch norm in the head replaced with Group-norm. The optimizer, best model selection based on CV, and other things are similar to my public kernel, and I was using 32-48 epochs, depending on the setup. In addition, I tried ResNet34, ResNeXt101, and EfficientNet, while all of them were performing worse. I think ResNet34 may be not capable enough for this task, while ResNeXt101 is too large to do training on my computer with sufficient bs.\n",
    "- The submission that gave me the 11th place (0.930 private LB/0.917 public LB) is based on a majority voting ensemble of 8 models (4 fold) with 6 TTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (D) fam_taro : 1st Place Solution [PND]\n",
    "https://www.kaggle.com/c/prostate-cancer-grade-assessment/discussion/169143 <br>\n",
    "https://github.com/kentaroy47/Kaggle-PANDA-1st-place-solution\n",
    "\n",
    "### Data preprocessing\n",
    "- Use Iafoss tile method & Qishen Ha bin label : How to make tiles? -> Split image by (tile_size, tile_size) -> Sort by pixel value for each tile -> Imgsize: ex. tile_size: 256, num_tile: 36 imsize: 256 x 6 = 1,536\n",
    "\n",
    "\n",
    "### Modeling\n",
    "- Model: EfficientNet B0-B1 with CELoss\n",
    "- 1. Split kfold with image similarity : imgid (imghash similarity greater than 0.9) in same fold <br>\n",
    "https://www.kaggle.com/yukkyo/imagehash-to-detect-duplicate-images-and-grouping\n",
    "- 2. Training with original label (with noise)\n",
    "- 3. Remove noise by prediction and original label gap(out of fold)\n",
    "- 4. Re-train model without noise\n",
    "- 5. Ensemble\n",
    "- Tile mode augmentation (train & test)\n",
    "- TTA(tile mode, hvflip, transpose)\n",
    "- Convert label to bin : ex. 2 → [1, 1, 0, 0, 0], 4 → [1, 1, 1, 1, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rohitsingh : PANDA - Inference (ENSEMBLE) trying various models\n",
    "https://www.kaggle.com/rohitsingh9990/panda-inference-ensemble-trying-various-models\n",
    "\n",
    "### Modeling\n",
    "1. se_resnext50_32x4d / 3 folds ensemble / full image resized (224x224) / LB: 0.66\n",
    "2. se_resnext50_32x4d / submitted on fold 0 / tiles of size (16x256x256) / CV: 0.7177 / LB: 0.67\n",
    "3. se_resnext50_32x4d / 5 folds ensemble / tiles of size (16x256x256) / CV: [ fold0: 0.717, fold1: 0.674, fold2: 0.692, fold3: 0.704, fold4: 0.695 ] / LB: 0.70\n",
    "4. efficientnet-B3 / 2 folds ensemble (fold 0 and fold 1) / tiles of size (16x256x256) / CV: [ fold0: 0.719, fold1: 0.726 ] / LB: 0.74\n",
    "5. efficientnet-B3 /  5 folds ensemble / tiles of size (16x256x256) / CV: [ fold0: 0.719, fold1: 0.726, fold2: 0.729, fold3: 0.719, fold4: 0.732 ] / LB: 0.73\n",
    "6. efficientnet-B3 / fold 0 / tiles of size (16x256x256) [image resized to 512x512] / CV: [ fold0: 0.749] / LB: 0.81\n",
    "7. efficientnet-B3 / ensemble of all 5 folds / tiles of size (16x256x256) [image resized to 512x512] / CV: [ fold0: 0.749, fold1: 0.7509, fold2: 0.7592, fold3: 0.7362, fold4: 0.7676] / LB: 0.84\n",
    "8. efficientnet-B3 / ensemble of all folds [0,1,2,4] / tiles of size (16x256x256) [image resized to 512x512] / CV: [ fold0: 0.749, fold1: 0.7509, fold2: 0.7592,fold4: 0.7676] / LB: 0.85\n",
    "\n",
    "*Interesting findings <br>\n",
    "\n",
    "- 1~3 : first used basic methods with resnext50, then used image preprocessing(tile method from above), and then used cross validation with 5 folds\n",
    "- 4~5 : used efficientnetb3, it's better than resnext50. 5 folds worked poorer than 2 folds\n",
    "- 6 : so tried 0 fold with image resizing, and it improved!\n",
    "- 7~8 : maybe it was with the image resizing, not cv. so with image resizing, tried 5 folds again. and tried selectively making an ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
